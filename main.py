import asyncio
import json
from datetime import datetime
from scraper import NewsletterScraper
from transcript_by_source import TranscriptBySource

async def main():
    scraper = NewsletterScraper()
    
    print("ğŸš€ DÃ©marrage du scraping des actualitÃ©s IA...")
    articles = await scraper.scrape_all_sources()
    
    print(f"\nâœ… {len(articles)} articles rÃ©cupÃ©rÃ©s (aprÃ¨s dÃ©dupplication)")
    
    # Rapport de statut
    status_report = scraper.get_status_report()
    print(f"\nğŸ“Š Rapport de statut:")
    print(f"   - Sources totales: {status_report['total_sources']}")
    print(f"   - Sources rÃ©ussies: {status_report['successful']}")
    print(f"   - Sources Ã©chouÃ©es: {status_report['failed']}")
    print(f"   - Articles totaux (avant dÃ©dupplication): {status_report['total_articles']}")
    
    if status_report['failed'] > 0:
        print(f"\nâŒ Sources en erreur:")
        for source, info in status_report['sources'].items():
            if info['status'] == 'failed':
                print(f"   - {source}: {info['error']}")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"data/raw_articles_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ Articles sauvegardÃ©s dans {output_file}")
    
    # Sauvegarder le rapport de statut
    status_file = f"data/status_report_{timestamp}.json"
    with open(status_file, 'w', encoding='utf-8') as f:
        json.dump(status_report, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š Rapport de statut sauvegardÃ© dans {status_file}")
    
    # GÃ©nÃ©rer les transcripts par source
    print(f"\nğŸ“‚ GÃ©nÃ©ration des transcripts par source...")
    source_transcripts = TranscriptBySource()
    saved_files = source_transcripts.save_transcripts_by_source(articles)
    
    print(f"\nâœ… Transcripts gÃ©nÃ©rÃ©s pour {len(saved_files)} sources")

if __name__ == "__main__":
    asyncio.run(main())