# AI Newsletter Scraper

Un systÃ¨me automatisÃ© pour collecter et organiser les derniÃ¨res actualitÃ©s en Intelligence Artificielle depuis diverses sources francophones et anglophones.

## ğŸš€ FonctionnalitÃ©s

- **Scraping multi-sources** : Collecte automatique depuis 19+ sources RSS et API
- **RÃ©cupÃ©ration de contenu complet** : Extraction intelligente du contenu complet pour les sources avec RSS tronquÃ©s
- **Extraction PDF arXiv** : RÃ©cupÃ©ration automatique du contenu des papers arXiv depuis les PDFs
- **Organisation par source** : GÃ©nÃ©ration de transcripts individuels par source
- **Rapport de statut** : Suivi des sources fonctionnelles et en erreur

## ğŸ“š Sources

### ActualitÃ©s gÃ©nÃ©rales
- ActuIA (FR)
- MIT Technology Review â€“ AI
- TechCrunch â€“ Artificial Intelligence
- KDnuggets
- MarkTechPost

### Recherche acadÃ©mique
- arXiv (cs.AI, cs.LG) - **Extraction automatique des PDFs**
- ScienceDaily â€“ AI
- Google AI Blog
- OpenAI Blog
- AIhub

### Nouveaux outils / produits
- Product Hunt â€“ AI
- Hugging Face Hub
- Reddit r/MachineLearning
- GitHub Trending

### Tendances marchÃ© / business
- AI Trends
- AI Business
- VentureBeat â€“ AI
- L'Usine Digitale â€“ IA

## âš ï¸ Limitations

Certaines sources ont des protections anti-scraping :
- **AI Business** : Utilise Cloudflare et bloque l'extraction automatique. Seul le contenu RSS (rÃ©sumÃ©) est disponible.

## ğŸ› ï¸ Installation

```bash
# Cloner le repository
git clone https://github.com/ai-fo/news.git
cd news

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“– Utilisation

### Scraping et gÃ©nÃ©ration de transcripts par source
```bash
python main.py
```

Cela va :
1. Scraper toutes les sources configurÃ©es
2. Sauvegarder les donnÃ©es brutes dans `data/`
3. GÃ©nÃ©rer des transcripts individuels dans `transcripts/[source]/`

Chaque source aura son propre dossier avec un transcript au format TXT contenant tous ses articles.

### GÃ©nÃ©rer uniquement les transcripts
Si vous avez dÃ©jÃ  des donnÃ©es scrappÃ©es :
```bash
python generate_transcripts_only.py
# ou avec un fichier spÃ©cifique
python generate_transcripts_only.py data/raw_articles_20250617_143022.json
```

## ğŸ“ Structure des fichiers

```
news/
â”œâ”€â”€ main.py                    # Point d'entrÃ©e principal
â”œâ”€â”€ scraper.py                 # Logique de scraping
â”œâ”€â”€ content_extractor.py       # Extraction de contenu depuis les pages web
â”œâ”€â”€ transcript_by_source.py    # GÃ©nÃ©ration des transcripts par source
â”œâ”€â”€ config.py                  # Configuration
â”œâ”€â”€ data/                      # DonnÃ©es brutes (JSON)
â””â”€â”€ transcripts/               # Transcripts gÃ©nÃ©rÃ©s
    â””â”€â”€ [source]/              # Un dossier par source
```

## âš™ï¸ Configuration

Modifiez `config.py` pour :
- Ajouter/supprimer des sources nÃ©cessitant l'extraction complÃ¨te
- Ajuster le nombre d'articles par source
- Modifier les timeouts et autres paramÃ¨tres

## ğŸ“Š Format des sorties

### Transcripts individuels (TXT)
- Un fichier par source avec tous ses articles
- Format structurÃ© avec mÃ©tadonnÃ©es complÃ¨tes
- Contenu wrappÃ© Ã  80 caractÃ¨res

### Rapport de statut (JSON)
- Sources rÃ©ussies/Ã©chouÃ©es
- Nombre d'articles collectÃ©s
- DÃ©tails des erreurs

## ğŸ¤ Contribution

Les contributions sont bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“ Licence

Ce projet est sous licence MIT.